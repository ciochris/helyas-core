# backend/autodev.py - Versione sicura e compatibile Railway

import os
import json
import ast
import subprocess
import tempfile
import signal
import requests
import re
import time
import base64
from flask import Blueprint, request, jsonify
from typing import List, Dict, Tuple

autodev_bp = Blueprint("autodev", __name__)

# === CONFIG ===
GITHUB_API = "https://api.github.com"
GITHUB_REPO = os.getenv("GITHUB_REPO", "ciochris/helyas-core")
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
BRANCH_DEV = "auto-dev"

# === LIMITS ===
MAX_TASK_SIZE = 5000
MAX_FILE_SIZE = 50000
MAX_FILES_PER_COMMIT = 10
API_TIMEOUT = 15
TEST_TIMEOUT = 30
RATE_LIMIT_DELAY = 1

# === SECURITY ===
DANGEROUS_IMPORTS = ['os.system', 'subprocess.call', 'eval', 'exec', '__import__']
SAFE_PATHS_PATTERN = re.compile(r'^[a-zA-Z0-9_/\-\.]+$')

class AutoDevManager:
    def __init__(self):
        if not GITHUB_TOKEN:
            raise ValueError("GITHUB_TOKEN environment variable required")
        
        self.headers = {
            "Authorization": f"token {GITHUB_TOKEN}",
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": "Helyas-AutoDev/1.0"
        }
        self.api_calls_count = 0
        self.last_api_call = 0

    def _rate_limit(self):
        """Enforce rate limiting for GitHub API"""
        self.api_calls_count += 1
        current_time = time.time()
        if current_time - self.last_api_call < RATE_LIMIT_DELAY:
            time.sleep(RATE_LIMIT_DELAY)
        self.last_api_call = time.time()

    def validate_task(self, task_data: dict) -> Tuple[bool, str]:
        """Comprehensive task validation"""
        if not isinstance(task_data, dict):
            return False, "Task must be a JSON object"

        required_fields = ["task_id", "objective", "constraints", "deliverables"]
        for field in required_fields:
            if field not in task_data:
                return False, f"Missing required field: {field}"

        if len(json.dumps(task_data)) > MAX_TASK_SIZE:
            return False, f"Task input too large (max {MAX_TASK_SIZE} chars)"

        objective = task_data.get("objective", "")
        if any(char in objective for char in [';', '|', '&', '`', '$']):
            return False, "Invalid characters in objective"

        task_id = task_data.get("task_id", "")
        if not re.match(r'^[a-zA-Z0-9_\-]+$', task_id):
            return False, "Invalid task_id format"

        return True, "Valid"

    def validate_generated_files(self, files: List[Dict]) -> Tuple[bool, str]:
        """Validate generated files for security"""
        if len(files) > MAX_FILES_PER_COMMIT:
            return False, f"Too many files (max {MAX_FILES_PER_COMMIT})"

        for file_obj in files:
            if not isinstance(file_obj, dict) or 'path' not in file_obj or 'content' not in file_obj:
                return False, "Invalid file object structure"

            path = file_obj['path']
            content = file_obj['content']

            if not SAFE_PATHS_PATTERN.match(path):
                return False, f"Invalid file path: {path}"
            if '..' in path or path.startswith('/'):
                return False, f"Unsafe file path: {path}"

            if len(content) > MAX_FILE_SIZE:
                return False, f"File too large: {path} (max {MAX_FILE_SIZE} chars)"

            if path.endswith('.py'):
                for dangerous in DANGEROUS_IMPORTS:
                    if dangerous in content:
                        return False, f"Dangerous code pattern detected: {dangerous}"

        return True, "Files validated"

    def execute_round_table(self, task_data: dict) -> Dict:
        """Execute round table - integrates with orchestrator"""
        try:
            from backend.orchestrator import round_table
            print("[AUTO-DEV] Attempting to import orchestrator...")
            result = round_table(task_data['objective'])
            files = []
            if result.get('decision', {}).get('proposal'):
                files.append({
                    "path": f"artifacts/generated_{task_data['task_id']}.py",
                    "content": f"# Auto-generated by Helyas Round Table\nprint('Generated code for {task_data['objective']}')\n"
                })
            files.append({
                "path": f"artifacts/summary_{task_data['task_id']}.md",
                "content": f"# Task Summary\n\nObjective: {task_data['objective']}\nDecision: {result.get('decision', {}).get('proposal', 'No decision')}\n"
            })
            return {"files": files, "summary": f"Generated artifacts for {task_data['objective']}"}
        except ImportError:
            return {
                "files": [{
                    "path": f"artifacts/mock_{task_data['task_id']}.py",
                    "content": f"# Mock generation for: {task_data['objective']}\nprint('Mock task completed')\n"
                }],
                "summary": f"Mock generation for {task_data['objective']}"
            }

    def run_golden_tests(self, files: List[Dict]) -> Tuple[bool, str]:
        """Golden tests without Popen timeout bug"""
        try:
            for file_obj in files:
                if file_obj['path'].endswith('.py'):
                    try:
                        ast.parse(file_obj['content'])
                    except SyntaxError as e:
                        return False, f"Syntax error in {file_obj['path']}: {e}"

                    tree = ast.parse(file_obj['content'])
                    for node in ast.walk(tree):
                        if isinstance(node, ast.Import):
                            for alias in node.names:
                                if alias.name in ['os', 'subprocess', 'sys']:
                                    return False, f"Restricted import in {file_obj['path']}: {alias.name}"

            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as temp_file:
                temp_file.write("print('Golden test execution OK')")
                temp_file.flush()

                proc = subprocess.Popen(
                    ["python3", temp_file.name],
                    stdout=subprocess.PIPE,
                    stderr=subprocess.PIPE,
                    preexec_fn=os.setsid
                )
                try:
                    stdout, stderr = proc.communicate(timeout=TEST_TIMEOUT)
                    if proc.returncode != 0:
                        return False, f"Execution test failed: {stderr.decode()}"
                except subprocess.TimeoutExpired:
                    os.killpg(os.getpgid(proc.pid), signal.SIGTERM)
                    return False, "Execution test timed out"
                finally:
                    os.unlink(temp_file.name)

            return True, "All golden tests passed"
        except Exception as e:
            return False, f"Golden tests failed: {str(e)}"

    def commit_to_branch(self, files: List[Dict], message: str) -> Tuple[bool, str]:
        """Atomic commit to auto-dev branch"""
        try:
            self._rate_limit()
            ref_url = f"{GITHUB_API}/repos/{GITHUB_REPO}/git/refs/heads/{BRANCH_DEV}"
            response = requests.get(ref_url, headers=self.headers, timeout=API_TIMEOUT)

            if response.status_code == 404:
                main_ref_url = f"{GITHUB_API}/repos/{GITHUB_REPO}/git/refs/heads/main"
                main_response = requests.get(main_ref_url, headers=self.headers, timeout=API_TIMEOUT)
                if main_response.status_code != 200:
                    return False, "Cannot access main branch"
                base_sha = main_response.json()["object"]["sha"]
                create_response = requests.post(
                    f"{GITHUB_API}/repos/{GITHUB_REPO}/git/refs",
                    headers=self.headers,
                    json={"ref": f"refs/heads/{BRANCH_DEV}", "sha": base_sha},
                    timeout=API_TIMEOUT
                )
                if create_response.status_code != 201:
                    return False, f"Cannot create branch {BRANCH_DEV}"
                current_sha = base_sha
            elif response.status_code == 200:
                current_sha = response.json()["object"]["sha"]
            else:
                return False, f"Cannot access branch {BRANCH_DEV}: {response.status_code}"

            tree_items = []
            for file_obj in files:
                self._rate_limit()
                blob_response = requests.post(
                    f"{GITHUB_API}/repos/{GITHUB_REPO}/git/blobs",
                    headers=self.headers,
                    json={
                        "content": base64.b64encode(file_obj['content'].encode()).decode(),
                        "encoding": "base64"
                    },
                    timeout=API_TIMEOUT
                )
                if blob_response.status_code != 201:
                    return False, f"Failed to create blob for {file_obj['path']}"
                blob_sha = blob_response.json()["sha"]
                tree_items.append({
                    "path": file_obj['path'],
                    "mode": "100644",
                    "type": "blob",
                    "sha": blob_sha
                })

            tree_response = requests.post(
                f"{GITHUB_API}/repos/{GITHUB_REPO}/git/trees",
                headers=self.headers,
                json={"base_tree": current_sha, "tree": tree_items},
                timeout=API_TIMEOUT
            )
            if tree_response.status_code != 201:
                return False, "Failed to create tree"
            tree_sha = tree_response.json()["sha"]

            commit_response = requests.post(
                f"{GITHUB_API}/repos/{GITHUB_REPO}/git/commits",
                headers=self.headers,
                json={
                    "message": f"[AUTO-DEV] {message}",
                    "tree": tree_sha,
                    "parents": [current_sha]
                },
                timeout=API_TIMEOUT
            )
            if commit_response.status_code != 201:
                return False, "Failed to create commit"
            commit_sha = commit_response.json()["sha"]

            update_response = requests.patch(
                ref_url,
                headers=self.headers,
                json={"sha": commit_sha},
                timeout=API_TIMEOUT
            )
            if update_response.status_code != 200:
                return False, "Failed to update branch"

            return True, f"Successfully committed {len(files)} files to {BRANCH_DEV}"
        except Exception as e:
            return False, f"Commit failed: {str(e)}"

    def notify_christian(self, message: str, status: str = "info"):
        timestamp = time.strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{timestamp}] [AUTO-DEV-{status.upper()}] {message}")


@autodev_bp.route("/autonomous-develop", methods=["POST"])
def autonomous_develop():
    start_time = time.time()
    try:
        if not GITHUB_TOKEN:
            return jsonify({"status": "error", "message": "GitHub integration not configured"}), 500

        manager = AutoDevManager()
        task_data = request.get_json(force=True)
        if not task_data:
            return jsonify({"status": "error", "message": "Invalid JSON input"}), 400

        valid, msg = manager.validate_task(task_data)
        if not valid:
            manager.notify_christian(f"Task validation failed: {msg}", "error")
            return jsonify({"status": "error", "message": msg}), 400

        manager.notify_christian(f"Starting autonomous development for: {task_data['objective']}")
        result = manager.execute_round_table(task_data)

        valid, file_msg = manager.validate_generated_files(result["files"])
        if not valid:
            manager.notify_christian(f"Generated files validation failed: {file_msg}", "error")
            return jsonify({"status": "error", "message": file_msg}), 500

        tests_passed, test_msg = manager.run_golden_tests(result["files"])
        if not tests_passed:
            manager.notify_christian(f"Golden tests failed: {test_msg}", "error")
            return jsonify({"status": "failed", "message": f"Tests failed: {test_msg}"}), 500

        commit_success, commit_msg = manager.commit_to_branch(result["files"], result["summary"])
        if not commit_success:
            manager.notify_christian(f"Commit failed: {commit_msg}", "error")
            return jsonify({"status": "failed", "message": f"Commit failed: {commit_msg}"}), 500

        elapsed = time.time() - start_time
        success_msg = f"Autonomous development completed in {elapsed:.2f}s"
        manager.notify_christian(success_msg, "success")

        return jsonify({
            "status": "success",
            "message": success_msg,
            "summary": result["summary"],
            "files_committed": len(result["files"]),
            "branch": BRANCH_DEV,
            "execution_time": elapsed
        })
    except Exception as e:
        error_msg = f"Autonomous development failed: {str(e)}"
        print(f"[AUTO-DEV-ERROR] {error_msg}")
        return jsonify({"status": "error", "message": error_msg}), 500
